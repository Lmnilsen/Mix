{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lmnilsen/Mix/blob/main/LMN_Homework_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7r7sc2OpZSmf"
      },
      "outputs": [],
      "source": [
        "###\n",
        "### Import dependencies. \n",
        "###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "### Load the LFW People dataset.\n",
        "###\n",
        "\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# Introspect the images arrays to find the shapes (for plotting).\n",
        "n_samples, h, w = lfw_people.images.shape\n",
        "\n",
        "# For machine learning we use the 2 data directly (as relative pixel\n",
        "# positions info is ignored by this model).\n",
        "X = lfw_people.data\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# The label to predict is the ID of the person.\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "n_classes = target_names.shape[0]\n",
        "\n",
        "# Only use 50% of the data.\n",
        "X = X[:int(X.shape[0] / 2)]\n",
        "y = y[:int(y.shape[0] / 2)]\n",
        "\n",
        "print(\"Total dataset size:\")\n",
        "print(\"Number of samples: %d\" % n_samples)\n",
        "print(\"Number of input features: %d\" % n_features)\n",
        "print(\"Number of classes: %d\" % n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9AphNDfZ4Rk",
        "outputId": "aae1a028-f7ee-4942-c0b2-22099cc40481"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size:\n",
            "Number of samples: 1288\n",
            "Number of input features: 1850\n",
            "Number of classes: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "### Split data into train and test sets.\n",
        "###\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "O5q_QzivZ8vX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "### Using RobustScaler to preprocess the input data\n",
        "### \n",
        "\n",
        "def transform_input_data(X, training=False):\n",
        "  \"\"\"\n",
        "  Preprocess the input data to work for your model.\n",
        "  \"\"\"\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "  scaler = RobustScaler()\n",
        "  X_processed = scaler.fit_transform(X)\n",
        "  return X_processed"
      ],
      "metadata": {
        "id": "sFk8Fbk9aFiR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "### Train and evaluate the model.\n",
        "###\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "\n",
        "X_train = transform_input_data(X_train, training=True)\n",
        "X_test = transform_input_data(X_test, training=False)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "print(\"F1 score: \", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zHWFhYda330",
        "outputId": "40da8af9-4e1f-4926-f915-67825906e51c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score:  0.8122093624733671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}